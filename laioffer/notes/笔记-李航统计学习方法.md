# 统计学习概论

## 1.2 监督学习

### 基本概念

在监督学习中：

输入空间 input space：输入所有可能取值的集合
输出空间 output space：输出所有可能取值的集合

实例 instance：每个具体的输入，通常由特征向量 feature vector 表示
特征空间 feature space：所有特征向量存在的空间， 特征向量的每一维对应于一个特征

输入输出变量用大写字母表示，习惯上输入变量， $X$, 输出变量，$Y$.
输入输出变量所取的值用小写字母表示，输入变量的取值，$x$，输出变量的取值，$y$.

本书中的向量均为列向量，输入实例 $x$ 的特征向量记作
$$x=\left(x^{(1)}, x^{(2)}, \cdots, x^{(i)}, \cdots, x^{(n)}\right)^{T}$$
$x^{(i)}$表示$x$的第$i$ 个特征，$x^{(i)}$和$x_{i}$不同，本书表示多个输入变量中的第$i$ 个，即
$$x_{i}=\left(x_{i}^{(1)}, x_{i}^{(2)}, \cdots, x_{i}^{(n)}\right)^{\mathrm{T}}$$

统计学习假设数据存在一定的统计规律，$X$ 和 $Y$具有联合概率分布的假设就是监督学习关于数据的基本假设。

监督学习的目的在与学习一个有输入到输出的映射。模型属于由输入空间到输出空间的映射的集合，这个集合就是**假设空间** hypothesis space。

监督学习的模型可以是概率模型或非概率模型，由条件概率分布 $\mathrm{P}(\mathrm{Y} \mid \mathrm{X})$ 或决策函数 decision function $\mathrm{Y}=\mathrm{f}(\mathrm{X})$表示，对具体的输入进行相应的输出预测时，写作

## 1.3 统计学习三要素

### 模型

在监督学习过程中，模型就是所有要学习的条件概率的分布或决策函数。

模型的假设空间 hypothesis space 包括所有可能的条件概率分布或决策函数。

### 策略

risk function(风险函数) or exprcted loss(期望损失)、

给定一个训练数据集，

$$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$$

模型$f(X)$关于训练数据集的平均损失称为经验损失 empirical risk 或经验损失 empirical loss

$$R_{\mathrm{emp}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)$$

期望风险$R_{\mathrm{exp}}(f)$ 是模型关于联合分布的期望损失，经验风险$R_{\mathrm{emp}}(f)$是模型关于训练样本集的平均损失。

**经验风险最小化** empirical risk minimization

$$\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)$$

其中，$\mathcal{F}$是假设空间

当样本容量足够大时，经验风险最小化能保证有很好的学习效果。
**极大似然估计** maximum likelihood estimation 就是经验等闲最小化的一个例子

当样本容量很小时，经验风险最小化学习的效果就未必很好，会产生过拟合 over-fitting 现象

结构风险最小化structual risk minimizatrion ,SRM 是为了防止过拟合而提出来的策略，结构风险最小化是等价于正则化 **regularization**

结构风险再经验风险上加上表示模型复杂度的正则化项 regularizer 或 罚项 penalty term

在假设空间，损失函数以及训练数据确定的情况下，**结构风险**的定义是
$$R_{\mathrm{srm}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)$$

其中 $J(f)$ 为模型的复杂度，是定义在假设空间 $\mathcal{F}$ 上的泛函, 模型越复杂，复杂度就越大。反之，模型 $f$ 越简单复杂度$J(f)$就越小。 也就是说，复杂度是对复杂函数的惩罚。$\lambda \geqslant 0$ 是系数，用以权衡经验风险和模型复杂度。

贝叶斯估计中的最大后验概率估计 maximum posterior probability estimation MAP 就是结构风险最小化的一个例子。

结构风险最小化的策略认为结构风险最小的模型是最优的模型，所以求最优模型，就是**求解最优化**问题：
$$\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)$$

这样，监督学习问题就变成了经验风险或结构风险函数的最优化问题。这时经验或结构风险函数是最优化的目标函数。

### 算法

算法是指学习模型的具体计算方法。统计学习方法之间的不同，主要来自其模型、策略、算法的不同。

## 1.4 模型估计和模型选择

### 训练误差与测试误差

当损失函数给定时，基于损失函数的模型的训练误差 training error 和模型的测试误差 test error 就成为学习方法评估的标准。**注意：** 统计学习方法具体采用的损失函数未必是评估时使用的损失函数。

假设模型是$Y=\hat{f}(X)$，**训练误差**是模型$Y=\hat{f}(X)$关于训练数据集的平均损失：
$$
R_{\mathrm{emp}}(\hat{f})=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right)
$$
其中，$N$ 是训练样本容量。

测试误差是模型$\mathrm{Y}=\hat{f}(\mathrm{X})$关于测试数据集的平均损失：
$$
e_{\text {test }}=\frac{1}{N^{\prime}} \sum_{i=1}^{N^{\prime}} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right)
$$
其中$N^{\prime}$是测试样本容量。

指示函数 indicator function, 即$\mathrm{y} \neq \hat{f}(\mathrm{x})$时为1，否则为0.

训练误差的大小，对判断给定的问题是不是一个容易学习的问题是有意义的，但本质上不重要。测试误差反映了学习方法对未知的测试数据集的预测能力，是学习中的重要概念。

通常将学习方法对未知数据的预测能力称为**泛化能力**（generalization ability）

### 过拟合和模型选择 overfitting and model selection 

过拟合是指学习是选择的模型所包含的参数过多，以至于出现这一模型对已知数据预测的很好，但对未知数据预测时很差的现象。

假设给定一个训练数据集：$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$
设 M 次多项式为：
$$
f_{M}(x, w)=w_{0}+w_{1} x+w_{2} x^{2}+\cdots+w_{M} x^{M}=\sum_{j=0}^{M} w_{j} x^{j}
$$
算式中$x$是单变量输入，$w_{0}, w_{1}, \cdots, w_{M}$是$M+1$个参数。

首先确定多项式的次数，然后再给定的模型复杂度下，按照经验风险最小化的策略，求解参数，即多项式系数，具体地，求一下经验风险最小化：
$$
L(w)=\frac{1}{2} \sum_{i=1}^{N}\left(f\left(x_{i}, w\right)-y_{i}\right)^{2}
$$
这时，损失函数为平方损失，系数 $\frac{1}{2}$ 是为了计算方便。
将模型与训练数据代入式中，有：
$$
L(w)=\frac{1}{2} \sum_{i=1}^{N}\left(\sum_{j=0}^{M} w_{j} x_{i}^{j}-y_{i}\right)^{2}
$$

对$w_{j}$求偏导数并令其为0，可得：
$$
w_{j}=\frac{\sum_{i=1}^{N} x_{i} y_{i}}{\sum_{i=1}^{N} x_{i}^{j+1}}, \quad j=0,1,2, \cdots, M
$$
于是求的拟合多项式系数$w_{0}^{*}, w_{1}^{*}, \cdots, w_{M}^{*}$。

**重点：** 模型选择是，不仅要考虑对一直数据的预测能力，而且还要考虑对未知数据的预测能力

下面介绍 **两种常用的模型选择方法：正则化与交叉验**

## 1.5 正则化与交叉验证

### 正则化 regularization

正则化 regularization 是结构风险最小化策略的实现，是在经验风险上加一个正则化项 regularizer 或者 罚项 penalty term。 正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大。一般形式：
$$
\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)
$$

正则化可以取不同的形式。

例如，回归问题中，损失函数是平方损失，正则化项可以参数向量的$L_{2}$范数：
$$
L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\frac{\lambda}{2}\|w\|^{2}
$$
这里，$\|w\|$ 表示参数向量$w$的$L_{2}$范数。

正则化也可以是参数向量的$L_{1}$范数：
$$
L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\lambda\|w\|_{1}
$$
这里，$\|w\|$ 表示参数向量$w$的$L_{1}$范数。

**正则化的作用**是选择经验风险与模型复杂度同时较小的模型。 ***奥卡姆剃刀原理***，在所有可能会选择的模型中，能够很好地解释一直数据并且十分简单才是最好的模型，也就是应该选择的模型。

### 交叉验证 cross validation

如果给定的样本数据充足，进行模型选择的一种简单方法是随机地将数据集切分成三部分，分别为训练集（training set）、验证集（validation set）和测试集（test set）。

- 简单交叉验证
- S折交叉验证 S-fold cross validation
- 留一交叉验证 leave-oneout cross validation

## 1.6 泛化能力

### 泛化误差

学习方法中的繁华能力 generalization ability 是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。

泛化误差定义：
如果学到的模型是$\hat{f}$，那么用这个模型对未知数据预测的误差即为泛化误差（generalization error）
$$
R_{\exp }(\hat{f})=E_{P}[L(Y, \hat{f}(X))]=\int_{\lambda \times y} L(y, \hat{f}(x)) P(x, y) \mathrm{d} x \mathrm{~d} y
$$
泛化误差反映了学习方法的泛化能力，如果一种方法学习的模型比另一种方法学习的模型具有更小的泛化误差，那么这种方法就更有效。事实上，泛化误差就是所学习到的模型的期望风险。

泛化误差上界 generalization error bound，就是通过比较两种学习方法的泛化误差上界来比较他们的优劣。

例子，二类分裂问题：

。已知训练数据集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，它是从联合概率分布 $P(X, Y)$ 独立同分布产生的，XεRn，Yε{-1,+1}。假设空间是函数的有限集合＝{f1，f2,…,fd}，d是函数个
数。设f是从中选取的函数。损失函数是0-1损失。关于f的**期望风险**和**经验风险**分别是
$$
R(f)=E[L(Y, f(X))]
$$
$$
\hat{R}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$
**经验风险最小函数**是：
$$
f_{N}=\arg \min _{f \in \mathcal{F}} \hat{R}(f)
$$
人们更关心的是的$f_{N}$的泛化能力：

$$
R\left(f_{N}\right)=E\left[L\left(Y, f_{N}(X)\right)\right]
$$

## 1.7 生成模型和判别模型

监督学习方法又可以分为生成方法（generative approach）和判别方法（discriminative approach）。所学到的模型分别称为生成模型（generative model）和判别模型（discriminative model）。

生成方法由数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：
$$
P(Y \mid X)=\frac{P(X, Y)}{P(X)}
$$

这种方式之所有成为生成方法，是因为模型表示给定输入$X$ 产生输出$Y$的生成关系。典型的生成模型有：**朴素贝叶斯法**和**隐马尔可夫模型**。

判别方法由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。判别方法关心的是对给定的输入X，应该预测什么样的输出Y。典型的判别模型包括：k近邻法、感知机、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法和条件随机场等。

**生成方法的特点**：生成方法可以还原出联合概率分布P(X,Y)，而判别方法则不能；生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型；当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用。

**判别方法的特点**：判别方法直接学习的是条件概率P(Y|X)或决策函数f(X)，直接面对预测，往往学习的准确率更高；由于直接学习P(Y|X)或f(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。

## 1.8 分类问题

在监督学习中，当输出变量Y取有限个离散值时，预测问题便成为分类问题，输入变量X可以是离散的，也可以是连续的。

监督学习从数据中学习一个分类模型或分类决策函数，称为分类器（classifier）。分类器对新的输入进行输出的预测（prediction），称为分类（classification）。可能的输出称为类（class）。分类的类别为多个时，称为多类分类问题。

评价分类器性能的指标一般是分类准确率（accuracy），其定义是：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。

对于二类分类问题常用的评价指标是精确率（precision）与召回率（recall）。

TP——将正类预测为正类数；
FN——将正类预测为负类数；
FP——将负类预测为正类数；
TN——将负类预测为负类数。

精确率定义为
$$
P=\frac{T P}{T P+F P}
$$
召回率定义为
$$
R=\frac{T P}{T P+F N}
$$
还有1F值，是精确率和召回率的调和均值，即
$$
\frac{2}{F_{1}}=\frac{1}{P}+\frac{1}{R}
$$
$$
F_{1}=\frac{2 T P}{2 T P+F P+F N}
$$
精确率和召回率都高时，F1值也会高。
许多统计学习方法可以用于分类，包括**k近邻法、感知机、朴素贝叶斯法、决策树、决策列表、逻辑斯谛回归模型、支持向量机、提升方法、贝叶斯网络、神经网络、Winnow**等.

## 1.9 标注问题 tagging

标注（tagging）也是一个监督学习问题。可以认为标注问题是分类问题的一个推广，标注问题又是更复杂的结构预测（structure prediction）问题的简单形式。

标注常用的统计学习方法有：隐马尔可夫模型、条件随机场。

## 1.10 回归问题 regression

回归问题的学习等价于函数拟合：选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据

回归问题按照输入变量的个数，分为**一元回归和多元回归**；按照输入变量和输出变量之间关系的类型即模型的类型，分为**线性回归和非线性回归**。

回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以由著名的**最小二乘法（least squares）**求解。

